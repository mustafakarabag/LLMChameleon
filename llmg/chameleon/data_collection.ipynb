{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebda5aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2\"  # Set to the GPU you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc81b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import pickle\n",
    "import collections\n",
    "from functools import partial\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from llmg.utils.mix import seed_all, prepare_dict_for_saving\n",
    "from llmg.chameleon.NaturalLanguageTalker.naturallanguagetalker import NaturalLanguageTalker\n",
    "from llmg.chameleon.NaturalLanguageTalker.HuggingfaceTalker import HuggingfaceTalker\n",
    "from llmg.chameleon.NaturalLanguageTalker.OpenaiTalker import OpenaiTalker\n",
    "from llmg.chameleon.NaturalLanguageTalker.GoogleGenaiTalker import GoogleGenaiTalker\n",
    "from llmg.chameleon.GamePlay import GamePlay\n",
    "from llmg.chameleon.constants import RESPOND_PROMPT\n",
    "from llmg.chameleon.utils import (\n",
    "    load_game_logs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebe4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config\n",
    "cfg = {\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"run_time\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3b386c",
   "metadata": {},
   "source": [
    "## Collect game data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059bc2e9",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68582e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data config\n",
    "cfg[\"data\"] = {\n",
    "    # ### Chameleon model config\n",
    "    # \"chameleon_cls\": GoogleGenaiTalker,\n",
    "    # # \"chameleon_cls\": OpenaiTalker,\n",
    "    # \"chameleon_kwargs\": {\n",
    "    #     \"model_id\": {\n",
    "    #         \"GPT-4o mini\": \"gpt-4o-mini-2024-07-18\",\n",
    "    #         \"GPT-4o\": \"gpt-4o-2024-08-06\",\n",
    "    #         \"GPT-4.1\": \"gpt-4.1-2025-04-14\",\n",
    "    #         \"GPT-5\": \"gpt-5-2025-08-07\",\n",
    "    #         \"Gemini-2.5-Flash\": \"gemini-2.5-flash\",\n",
    "    #         \"Gemini-2.5-Pro\": \"gemini-2.5-pro\",\n",
    "    #     }[(model_name := \"Gemini-2.5-Pro\")], # Change this to your model of choice !\n",
    "    #     # \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    #     \"api_key\": os.environ[\"GOOGLE_GENAI_API_KEY\"],\n",
    "    #     \"start_conversation\": False,\n",
    "    #     \"additional_generation_kwargs\": {\n",
    "    #         \"GPT-4o mini\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-4o\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-4.1\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-5\": {\n",
    "    #             \"max_output_tokens\": 5000,\n",
    "    #             \"temperature\": 1,\n",
    "    #             \"reasoning\": {\"effort\": \"low\"},\n",
    "    #         },\n",
    "    #         \"Gemini-2.5-Flash\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #             \"thinking_config\": {\n",
    "    #                 \"thinking_budget\": 0,\n",
    "    #             },\n",
    "    #         },\n",
    "    #         \"Gemini-2.5-Pro\": {\n",
    "    #             \"max_output_tokens\": 512 + 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #             \"thinking_config\": {\n",
    "    #                 \"thinking_budget\": 512,\n",
    "    #             },\n",
    "    #         },\n",
    "    #     }[model_name],\n",
    "    # },\n",
    "    \"chameleon_cls\": HuggingfaceTalker,\n",
    "    \"chameleon_kwargs\": {\n",
    "        # \"model_id\": \"Qwen/Qwen3-32B-AWQ\",\n",
    "        \"model_id\": \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\",\n",
    "        \"model\": None,  # Will be set later\n",
    "        \"tokenizer\": None,  # Will be set later\n",
    "        \"additional_generation_kwargs\": {\n",
    "            \"max_new_tokens\": 20,\n",
    "            \"do_sample\": False,\n",
    "            \"temperature\": None,\n",
    "            \"top_p\": None,\n",
    "            \"top_k\": None,\n",
    "        },\n",
    "        \"additional_generation_kwargs_hook_fns\": None,\n",
    "        \"hidden_states_layer_idx\": 40, # llama-3.1-70B\n",
    "        # \"hidden_states_layer_idx\": [30, 40], # qwen3 32b\n",
    "        \"hidden_states_token_idx\": 0,\n",
    "        \"start_conversation\": False,\n",
    "    },\n",
    "\n",
    "    \n",
    "    ### Non-chameleon model config\n",
    "    # # \"truthful_cls\": OpenaiTalker,\n",
    "    # \"truthful_cls\": GoogleGenaiTalker,\n",
    "    # \"truthful_kwargs\": {\n",
    "    #     \"model_id\": {\n",
    "    #         \"GPT-4o mini\": \"gpt-4o-mini-2024-07-18\",\n",
    "    #         \"GPT-4o\": \"gpt-4o-2024-08-06\",\n",
    "    #         \"GPT-4.1\": \"gpt-4.1-2025-04-14\",\n",
    "    #         \"GPT-5\": \"gpt-5-2025-08-07\",\n",
    "    #         \"Gemini-2.5-Flash\": \"gemini-2.5-flash\",\n",
    "    #         \"Gemini-2.5-Pro\": \"gemini-2.5-pro\",\n",
    "    #     }[(model_name := \"Gemini-2.5-Pro\")], # Change this to your model of choice !\n",
    "    #     # \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
    "    #     \"api_key\": os.environ[\"GOOGLE_GENAI_API_KEY\"],\n",
    "    #     \"start_conversation\": False,\n",
    "    #     \"additional_generation_kwargs\": {\n",
    "    #         \"GPT-4o mini\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-4o\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-4.1\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #         },\n",
    "    #         \"GPT-5\": {\n",
    "    #             \"max_output_tokens\": 5000,\n",
    "    #             \"temperature\": 1,\n",
    "    #             \"reasoning\": {\"effort\": \"low\"},\n",
    "    #         },\n",
    "    #         \"Gemini-2.5-Flash\": {\n",
    "    #             \"max_output_tokens\": 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #             \"thinking_config\": {\n",
    "    #                 \"thinking_budget\": 0,\n",
    "    #             },\n",
    "    #         },\n",
    "    #         \"Gemini-2.5-Pro\": {\n",
    "    #             \"max_output_tokens\": 512 + 20,\n",
    "    #             \"temperature\": 0,\n",
    "    #             \"thinking_config\": {\n",
    "    #                 \"thinking_budget\": 512,\n",
    "    #             },\n",
    "    #         },\n",
    "    #     }[model_name],\n",
    "    # },\n",
    "    \"truthful_cls\": HuggingfaceTalker,\n",
    "    \"truthful_kwargs\": {\n",
    "        # \"model_id\": \"Qwen/Qwen3-32B-AWQ\",\n",
    "        \"model_id\": \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\",\n",
    "        \"model\": None,  # Will be set later\n",
    "        \"tokenizer\": None,  # Will be set later\n",
    "        \"additional_generation_kwargs\": {\n",
    "            \"max_new_tokens\": 20,\n",
    "            \"do_sample\": False,\n",
    "            \"temperature\": None,\n",
    "            \"top_p\": None,\n",
    "            \"top_k\": None,\n",
    "        },\n",
    "        \"additional_generation_kwargs_hook_fns\": None,\n",
    "        # \"additional_generation_kwargs_hook_fns\": [ # Temperature=1\n",
    "        #     lambda locs: \\\n",
    "        #         dict() if len(locs[\"messages\"]) == 0 or RESPOND_PROMPT[-40:].lower() not in locs[\"messages\"][-1][\"content\"].lower() \\\n",
    "        #         else {\"temperature\": 1.0, \"do_sample\": True}\n",
    "        # ],\n",
    "        \"hidden_states_layer_idx\": 40,\n",
    "        \"hidden_states_token_idx\": 0,\n",
    "        \"start_conversation\": False,\n",
    "        # \"steering_kwargs\": {\n",
    "        #     \"steering_vector\": torch.load(os.path.join(os.environ[\"DATA_DIR\"], \"chameleon\", f\"steering_vector_2025-08-15_15-31.pt\"), map_location=\"cpu\"),\n",
    "        #     \"steering_strength\": -16,  # Adjust the steering strength as needed (negative for more concealing, positive for more information-revealing)\n",
    "        #     \"layer_index\": 40,  # Layer to apply steering\n",
    "        #     \"token_index\": -1,  # Token index to apply steering\n",
    "        #     \"selection_fn\": lambda locs: \\\n",
    "        #         RESPOND_PROMPT[-40:].lower() in locs[\"messages\"][-1][\"content\"].lower() if \"messages\" in locs and len(locs[\"messages\"]) > 0 else False,\n",
    "        # },\n",
    "    },\n",
    "\n",
    "    \"num_of_trials\": 100,\n",
    "    \"num_of_players\": 4,\n",
    "    \"num_possible_words\": 16,\n",
    "    \"chameleon_cards_path\": \"chameleon_cards.pkl\",\n",
    "    \"add_intro_msg\": False,\n",
    "    \"send_intro_msg_to_llm\": False,\n",
    "    \"nonchameleons_response_word_instruction\": None, # Instruction to conceal\n",
    "    # \"nonchameleons_response_word_instruction\": \"On a scale of 1 to 10, where 1 is very cryptic and concealing, and 10 is highly information-revealing, your strategy should be around 1.\",\n",
    "\n",
    "    \"start_at_trial\": 0, # Which trial number to start from\n",
    "    \"load_game_inits_from\": None,\n",
    "\n",
    "    \"save_subpath\": f\"chameleon/{cfg['run_time']}\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29afb32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load game configurations from other game logs\n",
    "cfg[\"data\"][\"load_game_inits_from\"] = None\n",
    "# cfg[\"data\"][\"load_game_inits_from\"] = os.path.join(os.environ[\"DATA_DIR\"], \"chameleon\", \"2025-08-13_19-55\")\n",
    "\n",
    "if cfg[\"data\"][\"load_game_inits_from\"] is not None:\n",
    "    ckpt_game_logs = load_game_logs(\n",
    "        [cfg[\"data\"][\"load_game_inits_from\"]],\n",
    "        layer_to_probe=None,\n",
    "        token_to_probe=None,\n",
    "        max_games=cfg[\"data\"][\"num_of_trials\"],\n",
    "        verbose=0,\n",
    "    )\n",
    "    print(f\"Loaded {len(ckpt_game_logs)} checkpoint game logs from {cfg['data']['load_game_inits_from']}\")\n",
    "else:\n",
    "    print(f\"Not loading any checkpoint game logs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb1d11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models and tokenizers\n",
    "from transformers import modeling_utils\n",
    "if not hasattr(modeling_utils, \"ALL_PARALLEL_STYLES\") or modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\",\"colwise\",'rowwise']\n",
    "\n",
    "if cfg[\"data\"][\"chameleon_cls\"] == HuggingfaceTalker:\n",
    "    cfg[\"data\"][\"chameleon_kwargs\"][\"tokenizer\"] = AutoTokenizer.from_pretrained(\n",
    "        cfg[\"data\"][\"chameleon_kwargs\"][\"model_id\"],\n",
    "        trust_remote_code=True\n",
    "    )\n",
    "    cfg[\"data\"][\"chameleon_kwargs\"][\"model\"] = AutoModelForCausalLM.from_pretrained(\n",
    "        cfg[\"data\"][\"chameleon_kwargs\"][\"model_id\"],\n",
    "        trust_remote_code=True,\n",
    "        device_map=\"auto\"\n",
    "    )\n",
    "    cfg[\"data\"][\"chameleon_kwargs\"][\"model\"] = cfg[\"data\"][\"chameleon_kwargs\"][\"model\"].eval()\n",
    "elif cfg[\"data\"][\"chameleon_cls\"] == OpenaiTalker:\n",
    "    print(f\"[INFO] Using OpenAI API for Chameleon model\")\n",
    "elif cfg[\"data\"][\"chameleon_cls\"] == GoogleGenaiTalker:\n",
    "    print(f\"[INFO] Using Google GenAI API for Chameleon model\")\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported chameleon player type: {cfg['data']['chameleon_cls']}\")\n",
    "\n",
    "if cfg[\"data\"][\"truthful_cls\"] == HuggingfaceTalker:\n",
    "    if cfg[\"data\"][\"chameleon_kwargs\"][\"model_id\"] == cfg[\"data\"][\"truthful_kwargs\"][\"model_id\"]:\n",
    "        # Use shared model with different message history\n",
    "        print(f\"[INFO] Using the same model for Chameleon and Truthful player: {cfg['data']['chameleon_kwargs']['model_id']}\")\n",
    "        cfg[\"data\"][\"truthful_kwargs\"][\"tokenizer\"] = cfg[\"data\"][\"chameleon_kwargs\"][\"tokenizer\"]\n",
    "        cfg[\"data\"][\"truthful_kwargs\"][\"model\"] = cfg[\"data\"][\"chameleon_kwargs\"][\"model\"]\n",
    "    else:\n",
    "        # Load separate model for Truthful player\n",
    "        cfg[\"data\"][\"truthful_kwargs\"][\"tokenizer\"] = AutoTokenizer.from_pretrained(\n",
    "            cfg[\"data\"][\"truthful_kwargs\"][\"model_id\"],\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        cfg[\"data\"][\"truthful_kwargs\"][\"model\"] = AutoModelForCausalLM.from_pretrained(\n",
    "            cfg[\"data\"][\"truthful_kwargs\"][\"model_id\"],\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        cfg[\"data\"][\"truthful_kwargs\"][\"model\"].eval()\n",
    "elif cfg[\"data\"][\"truthful_cls\"] == OpenaiTalker:\n",
    "    print(f\"[INFO] Using OpenAI API for Truthful model\")\n",
    "elif cfg[\"data\"][\"truthful_cls\"] == GoogleGenaiTalker:\n",
    "    print(f\"[INFO] Using Google GenAI API for Truthful model\")\n",
    "else:\n",
    "    raise ValueError(f\"Unsupported truthful player type: {cfg['data']['truthful_cls']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec6c156",
   "metadata": {},
   "source": [
    "### Gameplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34eb1d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up data collection configuration and tracking\n",
    "tested_chameleon_types = [\n",
    "    [cfg[\"data\"][\"chameleon_cls\"], cfg[\"data\"][\"chameleon_kwargs\"]]\n",
    "]\n",
    "tested_truthful_types = [\n",
    "    [cfg[\"data\"][\"truthful_cls\"], cfg[\"data\"][\"truthful_kwargs\"]]\n",
    "]\n",
    "all_results = dict() # Dictionary to store the results. Each key corresponds to a chameleon-truthful player type combination\n",
    "verbose = True\n",
    "compute_posterior_probabilities = False # Set True to compute the posterior probabilities for each response\n",
    "\n",
    "# Prepare the save directory\n",
    "cfg[\"data\"][\"save_to_dir\"] = os.path.join(os.environ[\"DATA_DIR\"], cfg[\"data\"][\"save_subpath\"])\n",
    "os.makedirs(cfg[\"data\"][\"save_to_dir\"], exist_ok=True)\n",
    "print(f\"Generating data for {cfg['data']['num_of_trials']} trials\")\n",
    "print(f\"Saving to {cfg['data']['save_to_dir']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b1769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the chameleon truthful player combination\n",
    "global_run_idx = 0\n",
    "for chameleon_type in tested_chameleon_types:\n",
    "    for truthful_type in tested_truthful_types:\n",
    "        seed_all(cfg[\"seed\"])\n",
    "        \n",
    "        # Counts for the game result stats\n",
    "        num_of_valid_trials = 0\n",
    "        num_of_chameleon_identified = 0\n",
    "        num_of_chameleon_loses = 0\n",
    "\n",
    "        results = dict() # Dictionary to store the results of each combination\n",
    "        game_logs = [] # List to keep each game log\n",
    "\n",
    "        print(f'Chameleon type: {chameleon_type[0].__name__} {chameleon_type[1][\"model_id\"]}, Truthful type: {truthful_type[0].__name__} {truthful_type[1][\"model_id\"]}')\n",
    "        for run in tqdm(range(cfg[\"data\"][\"start_at_trial\"], cfg[\"data\"][\"num_of_trials\"]), desc='Games played'):\n",
    "            # Determine the chameleon index uniformly randomly\n",
    "            chameleon_index = random.randint(0, cfg[\"data\"][\"num_of_players\"] - 1)\n",
    "\n",
    "            # Initiate players based on identities\n",
    "            players = []\n",
    "            for i in range(cfg[\"data\"][\"num_of_players\"]):\n",
    "                if i == chameleon_index:\n",
    "                    players.append(chameleon_type[0](**chameleon_type[1]))\n",
    "                else:\n",
    "                    players.append(truthful_type[0](**truthful_type[1]))\n",
    "\n",
    "            # Initiate conversation\n",
    "            for player in players:\n",
    "                player.start_conversation(\n",
    "                    add_intro_message=cfg[\"data\"][\"add_intro_msg\"],\n",
    "                    send_to_assistant=cfg[\"data\"][\"send_intro_msg_to_llm\"],\n",
    "                )\n",
    "\n",
    "            # Create the game. The category and the secret word are chosen\n",
    "            game = GamePlay(\n",
    "                players,\n",
    "                chameleon_index=chameleon_index,\n",
    "                num_of_possible_words=cfg[\"data\"][\"num_possible_words\"],\n",
    "                chameleon_cards_path=cfg[\"data\"][\"chameleon_cards_path\"],\n",
    "                init_from_ckpt=ckpt_game_logs[run] if cfg[\"data\"][\"load_game_inits_from\"] is not None else None,\n",
    "                nonchameleons_response_word_instruction=cfg[\"data\"][\"nonchameleons_response_word_instruction\"],\n",
    "            )\n",
    "\n",
    "            # Game result\n",
    "            game_result, game, explanation, last_responses = game.play()\n",
    "\n",
    "            if compute_posterior_probabilities:\n",
    "                # Create auxilary SCoRe player to compute posterior probabilities\n",
    "                aux_player = SCoRe()\n",
    "                aux_player.get_category(game.category, game.possible_words)\n",
    "                aux_player.responses = [game.word_responses[i] for i in range(1, game.num_of_players+1)]\n",
    "\n",
    "                # Compute the posterior probabilities for each response\n",
    "                initial_prior_probabilities = np.ones(len(game.possible_words)) / len(game.possible_words)\n",
    "                probability_list = []\n",
    "                probability_list.append(initial_prior_probabilities)\n",
    "                for i in range(len(game.word_responses) - 1):\n",
    "                    responses_without_chameleon = [game.word_responses[j] for j in range(1, game.num_of_players+1) if j != game.chameleon_index+1]\n",
    "                    posterior_probabilities = aux_player.compute_posterior_probabilities(initial_prior_probabilities, responses_without_chameleon[:i+1])\n",
    "                    probability_list.append(posterior_probabilities)\n",
    "\n",
    "                print(probability_list)\n",
    "\n",
    "            # Result counter from the truthful players' pov\n",
    "            if game_result == 'IdentifiedWin':\n",
    "                num_of_chameleon_identified += 1\n",
    "                num_of_chameleon_loses += 1\n",
    "                num_of_valid_trials += 1\n",
    "            elif game_result == 'IdentifiedLoss':\n",
    "                num_of_chameleon_identified += 1\n",
    "                num_of_valid_trials += 1\n",
    "            elif game_result == 'MisidentifiedLoss':\n",
    "                num_of_valid_trials += 1\n",
    "\n",
    "            if verbose:\n",
    "                print(\"=================================================================================\")\n",
    "                print('Game result: ' + game_result)\n",
    "                print('Explanation: ' + explanation)\n",
    "                print('Category: ' + game.category)\n",
    "                print('Possible words: ' + str(game.possible_words))\n",
    "                print('Secret word: ' + game.secret_word)\n",
    "                print('Chameleon index: ' + str(game.chameleon_index + 1))\n",
    "                print('Player types: ' + str([player.__class__.__name__ + ' ' + player.model_id for player in game.players]))\n",
    "                print('Game word responses: ' + str(game.word_responses))\n",
    "                print('Votes: ' + str(game.votes))\n",
    "                print('Voted chameleon: ' + str(game.voted_chameleon))\n",
    "                print('Chameleon response: ' + str(game.chameleon_response))\n",
    "                print(f'Game played {run+1} times.')\n",
    "                print(f'Valid games: {num_of_valid_trials} out of {run+1}')\n",
    "                print(f'Number of times the chameleon was identified: {num_of_chameleon_identified}')\n",
    "                print(f'Number of times the chameleon loses: {num_of_chameleon_loses}')\n",
    "                print(\"=================================================================================\")\n",
    "\n",
    "            game_dict = {'game_result': game_result, 'explanation': explanation, 'category': game.category, 'possible_words': game.possible_words, 'secret_word': game.secret_word, 'chameleon_index': game.chameleon_index, 'word_responses': game.word_responses, 'votes': game.votes, 'voted_chameleon': game.voted_chameleon, 'chameleon_response': game.chameleon_response, 'messages': [player.messages for player in game.players]}\n",
    "            game_dict['player_types'] = [player.__class__.__name__ + ' ' +  player.model_id for player in game.players]\n",
    "            game_dict['config'] = prepare_dict_for_saving(cfg[\"data\"])\n",
    "            if compute_posterior_probabilities:\n",
    "                game_dict['posterior_probabilities'] = probability_list\n",
    "\n",
    "            # Save\n",
    "            if cfg[\"data\"][\"save_to_dir\"] is not None:\n",
    "                with open(os.path.join(cfg[\"data\"][\"save_to_dir\"], f'game_{global_run_idx}.pkl'), 'wb') as f:\n",
    "                    pickle.dump(game_dict, f)\n",
    "            else:\n",
    "                game_logs.append(game_dict)\n",
    "            global_run_idx += 1\n",
    "\n",
    "        # Print results for the chameleon-truthful player combination\n",
    "        print(f'Chameleon type: {chameleon_type[0].__name__} {chameleon_type[1]}, Truthful type: {truthful_type[0].__name__} {truthful_type[1]}')\n",
    "        print(f'Number of games: {cfg[\"data\"][\"num_of_trials\"]}')\n",
    "        print(f'Valid games: {num_of_valid_trials}')\n",
    "        print(f'Number of times the chameleon was identified: {num_of_chameleon_identified}')\n",
    "        print(f'Number of times the chameleon loses: {num_of_chameleon_loses}')\n",
    "        if num_of_valid_trials > 0:\n",
    "            print(f'Non-chameleon win ratio: {num_of_chameleon_loses/max(1,num_of_valid_trials)}')\n",
    "            print(f'Identification ratio {num_of_chameleon_identified/max(1,num_of_valid_trials)}')\n",
    "        if num_of_chameleon_identified > 0:\n",
    "            print(f'Second round win ratio {1 - num_of_chameleon_loses/max(1,num_of_chameleon_identified)}')\n",
    "        print('\\n')\n",
    "\n",
    "        # Save the results in the dictionary\n",
    "        results['game_logs'] = game_logs\n",
    "        results['num_of_players'] = cfg[\"data\"][\"num_of_players\"]\n",
    "        results['num_of_trials'] = cfg[\"data\"][\"num_of_trials\"]\n",
    "        results['num_of_valid_trials'] = num_of_valid_trials\n",
    "        results['num_of_chameleon_identified'] = num_of_chameleon_identified\n",
    "        results['num_of_chameleon_loses'] = num_of_chameleon_loses\n",
    "        all_results[(chameleon_type[0].__name__ + ' ' +  str(chameleon_type[1]), truthful_type[0].__name__ + ' ' + str(truthful_type[1]) )] = results\n",
    "\n",
    "        # Save the game logs in a pickle file with timestamp\n",
    "        with open(os.path.join(cfg[\"data\"][\"save_to_dir\"], f'partial_results.pkl'), 'wb') as f:\n",
    "            pickle.dump(all_results, f)\n",
    "\n",
    "# Save the game logs in a pickle file\n",
    "with open(os.path.join(cfg[\"data\"][\"save_to_dir\"], f'final_results.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_results, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
