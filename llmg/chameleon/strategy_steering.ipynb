{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c06eac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"  # Set to the GPU you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b90c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import datetime\n",
    "import traceback\n",
    "import random\n",
    "import pickle\n",
    "import collections\n",
    "from functools import partial\n",
    "import dill\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import itertools\n",
    "import lovely_tensors as lt\n",
    "lt.monkey_patch()\n",
    "\n",
    "from llmg.utils.mix import seed_all\n",
    "from llmg.utils.steering import SteeringHook\n",
    "from llmg.chameleon.NaturalLanguageTalker.HuggingfaceTalker import HuggingfaceTalker\n",
    "from llmg.chameleon.constants import (\n",
    "    GAME_START_PROMPT,\n",
    "    DISTRIBUTE_INDICES_PROMPT,\n",
    "    DISTRIBUTE_CHAMELEON_IDENTITY_PROMPT,\n",
    "    DISTRIBUTE_NON_CHAMELEON_IDENTITY_PROMPT,\n",
    "    DISTRIBUTE_CATEGORY_PROMPT,\n",
    "    RESPOND_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34faa547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global config\n",
    "cfg = {\n",
    "    \"seed\": 0,\n",
    "    \"device\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"run_time\": datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M\"),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ecee7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steering config\n",
    "cfg[\"steering\"] = {\n",
    "    ### Data collection config\n",
    "    # \"model_name\": \"Qwen/Qwen3-32B-AWQ\",\n",
    "    \"model_name\": \"hugging-quants/Meta-Llama-3.1-70B-Instruct-AWQ-INT4\",\n",
    "    \"layer_idx\": 40,\n",
    "    # \"layer_idx\": [30, 40, 50],  # For Qwen3-32B\n",
    "    \"token_idx\": 0,\n",
    "    \"generation_kwargs\": {\n",
    "        \"max_new_tokens\": 20,\n",
    "        \"do_sample\": False,\n",
    "        \"temperature\": None,\n",
    "        \"top_p\": None,\n",
    "        \"top_k\": None,\n",
    "    },\n",
    "    \"cards_path\": \"chameleon_cards.pkl\",\n",
    "    \"save_path\": os.path.join(os.environ[\"DATA_DIR\"], f\"chameleon/steering/{cfg['run_time']}.pkl\"),\n",
    "}\n",
    "os.makedirs(os.path.dirname(cfg[\"steering\"][\"save_path\"]), exist_ok=True)\n",
    "print(f\"Steering save path:\\n{cfg['steering']['save_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934d0851",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beee680",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model and tokenizer\n",
    "from transformers import modeling_utils\n",
    "if not hasattr(modeling_utils, \"ALL_PARALLEL_STYLES\") or modeling_utils.ALL_PARALLEL_STYLES is None:\n",
    "    modeling_utils.ALL_PARALLEL_STYLES = [\"tp\", \"none\",\"colwise\",'rowwise']\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(cfg[\"steering\"][\"model_name\"], trust_remote_code=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(cfg[\"steering\"][\"model_name\"], trust_remote_code=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193e4975",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load chameleon cards\n",
    "with open(cfg[\"steering\"][\"cards_path\"], \"rb\") as f:\n",
    "    chameleon_cards = pickle.load(f)\n",
    "print(f\"Loaded {len(chameleon_cards)} chameleon cards from {cfg['steering']['cards_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d56dae3",
   "metadata": {},
   "source": [
    "### Instructions + categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c396667",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup for collecting data for strategy steering\n",
    "cfg[\"steering\"][\"strategy_prompt\"] = \"\"\"\n",
    "On a scale of 1 to 10, where 1 is very cryptic and concealing, and 10 is highly information-revealing, your strategy should be around {strategy_level}.\n",
    "\"\"\".strip()\n",
    "\n",
    "seed_all(cfg[\"seed\"])\n",
    "\n",
    "# Generate combinations of game state options\n",
    "cfg[\"steering\"][\"game_state_opts\"] = {\n",
    "    \"num_players\": [3, 4, 5, 6],\n",
    "    # \"num_players\": [4, 6],  # Full analysis\n",
    "    # \"categories\": list(chameleon_cards.keys()), # Full analysis\n",
    "    # \"categories\": [\"Famous Islands\"], # If you want to test a specific category\n",
    "    # \"categories\": [\"School\"], # If you want to test a specific category\n",
    "    \"categories\": [list(chameleon_cards.keys())[random.randint(0, len(chameleon_cards) - 1)]],\n",
    "    \"is_chameleon\": [False],\n",
    "}\n",
    "opt_combinations = [\n",
    "    dict(zip(cfg[\"steering\"][\"game_state_opts\"].keys(), v))\n",
    "    for v in itertools.product(*cfg[\"steering\"][\"game_state_opts\"].values())\n",
    "]\n",
    "\n",
    "cfg[\"steering\"][\"instruction_opts\"] = [\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=1) + \" \", 1),\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=3) + \" \", 3),\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=5) + \" \", 5),\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=7) + \" \", 7),\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=9) + \" \", 9),\n",
    "    (cfg[\"steering\"][\"strategy_prompt\"].format(strategy_level=10) + \" \", 10),\n",
    "]\n",
    "\n",
    "# Randomly select K combinations\n",
    "seed_all(cfg[\"seed\"])\n",
    "cfg[\"steering\"][\"max_k_combinations\"] = 300\n",
    "random.shuffle(opt_combinations)\n",
    "cfg[\"steering\"][\"opt_combinations\"] = opt_combinations[:cfg[\"steering\"][\"max_k_combinations\"]]\n",
    "print(f\"Selected {len(cfg['steering']['opt_combinations'])} combinations for probing.\")\n",
    "print(f\"Combined with instruction options results in {len(cfg['steering']['opt_combinations']) * len(cfg['steering']['instruction_opts'])} total probing data points.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e940c657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_game_msg_list(\n",
    "    num_players,\n",
    "    player_number,\n",
    "    category,\n",
    "    secret_words,\n",
    "    secret_word,\n",
    "    is_chameleon,\n",
    "    instruction,\n",
    "):\n",
    "    msgs = []\n",
    "    msgs.append({\"role\": \"user\", \"content\": GAME_START_PROMPT.format(num_players=num_players)})\n",
    "    msgs.append({\"role\": \"assistant\", \"content\": \"yes\"})\n",
    "    \n",
    "    msgs.append({\"role\": \"user\", \"content\": DISTRIBUTE_CATEGORY_PROMPT.format(category=category, possible_words=\", \".join(secret_words))})\n",
    "    msgs.append({\"role\": \"assistant\", \"content\": \"yes\"})\n",
    "    \n",
    "    msgs.append({\"role\": \"user\", \"content\": DISTRIBUTE_INDICES_PROMPT.format(player_number=player_number)})\n",
    "    msgs.append({\"role\": \"assistant\", \"content\": str(player_number)})\n",
    "\n",
    "    if is_chameleon:\n",
    "        msgs.append({\"role\": \"user\", \"content\": DISTRIBUTE_CHAMELEON_IDENTITY_PROMPT})\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": \"yes\"})\n",
    "    else:\n",
    "        msgs.append({\"role\": \"user\", \"content\": DISTRIBUTE_NON_CHAMELEON_IDENTITY_PROMPT.format(secret_word=secret_word)})\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": \"no\"})\n",
    "\n",
    "    msgs.append({\"role\": \"user\", \"content\": RESPOND_PROMPT.format(previous_words=\"\", instruction=instruction).strip()})\n",
    "    return msgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5204ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect instruction messages\n",
    "seed_all(cfg[\"seed\"])\n",
    "instruct_msg_dicts = []\n",
    "for opt_i, opt in enumerate(cfg[\"steering\"][\"opt_combinations\"]):\n",
    "    if opt_i % 10 == 0:\n",
    "        print(f\"Processing option {opt_i + 1}/{len(cfg['steering']['opt_combinations'])}: {opt}\")\n",
    "\n",
    "    # Pick secret word\n",
    "    possible_secret_words = chameleon_cards[opt[\"categories\"]]\n",
    "    secret_word = random.choice(possible_secret_words)\n",
    "\n",
    "    # Generate messages for each possible instruction\n",
    "    for (instruction_str, info_revealing_level) in cfg[\"steering\"][\"instruction_opts\"]:\n",
    "        # Construct the game message list\n",
    "        msgs = construct_game_msg_list(\n",
    "            num_players=opt[\"num_players\"] - 1,\n",
    "            player_number=\"1\",\n",
    "            category=opt[\"categories\"],\n",
    "            secret_words=possible_secret_words,\n",
    "            secret_word=secret_word,\n",
    "            is_chameleon=opt[\"is_chameleon\"],\n",
    "            instruction=instruction_str,\n",
    "        )\n",
    "\n",
    "        # Collect hidden states from the model\n",
    "        talker = HuggingfaceTalker(\n",
    "            model_id=model.name_or_path,\n",
    "            model=model,\n",
    "            tokenizer=tokenizer,\n",
    "            additional_generation_kwargs=cfg[\"steering\"][\"generation_kwargs\"],\n",
    "            hidden_states_layer_idx=cfg[\"steering\"][\"layer_idx\"],\n",
    "            hidden_states_token_idx=cfg[\"steering\"][\"token_idx\"],\n",
    "            start_conversation=False,\n",
    "        )\n",
    "        response_dict = talker.get_llm_response_and_hidden_states(\n",
    "            messages=msgs,\n",
    "            max_new_tokens=cfg[\"steering\"][\"generation_kwargs\"][\"max_new_tokens\"],\n",
    "            return_logprobs=True,\n",
    "            get_all_logprobs=True,\n",
    "        )\n",
    "        response_text, hidden_states = response_dict[\"content\"], response_dict[\"hidden_states\"]\n",
    "        logprobs = response_dict.get(\"logprobs\", None)\n",
    "\n",
    "        instruct_msg_dicts.append({\n",
    "            \"messages\": msgs,\n",
    "            \"category\": opt[\"categories\"],\n",
    "            \"num_players\": opt[\"num_players\"],\n",
    "            \"is_chameleon\": opt[\"is_chameleon\"],\n",
    "            \"player_number\": \"1\",\n",
    "            \"secret_word\": secret_word,\n",
    "            \"instruction\": instruction_str,\n",
    "            \"info_revealing_level\": info_revealing_level,\n",
    "            \"response_text\": response_text,\n",
    "            \"hidden_states\": hidden_states,\n",
    "            \"logprobs\": logprobs,\n",
    "            \"config\": cfg,\n",
    "        })\n",
    "\n",
    "# Save the instruction messages\n",
    "with open(cfg[\"steering\"][\"save_path\"], \"wb\") as f:\n",
    "    pickle.dump(instruct_msg_dicts, f)\n",
    "print(f\"Saved {len(instruct_msg_dicts)} instruction messages to:\\n{cfg['steering']['save_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5236f1",
   "metadata": {},
   "source": [
    "## Analyze data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e3f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the instruction messages\n",
    "for i in range(len(instruct_msg_dicts)):\n",
    "    print(f\"Instruction {i+1}:\")\n",
    "    for m in instruct_msg_dicts[i][\"messages\"]:\n",
    "        print(m[\"content\"])\n",
    "    print(\"Response:\", instruct_msg_dicts[i][\"response_text\"])\n",
    "    print(\"Info Revealing Level:\", instruct_msg_dicts[i][\"info_revealing_level\"])\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d345e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previously collected data for plotting\n",
    "## With instructions\n",
    "with open(os.path.join(os.environ[\"DATA_DIR\"], \"chameleon/steering/2025-07-24_13-09.pkl\"), \"rb\") as f:\n",
    "    instruct_msg_dicts = pickle.load(f)\n",
    "\n",
    "## Without instructions (steering)\n",
    "with open(os.path.join(os.environ[\"DATA_DIR\"], \"chameleon/steering/2025-08-12_15-23.pkl\"), \"rb\") as f:\n",
    "    no_instruct_msg_dicts = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130b97a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PCA of strategy hidden states\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Filter out unwanted info revealing levels\n",
    "remove_num_of_players = []\n",
    "remove_info_levels = []\n",
    "add_steering_vec = True # !!! Make sure you have already computed the steering vector computed in the cell below !!!\n",
    "hidden_state_idx = 0  # Index of the hidden state to use for PCA\n",
    "# steer_by_opts = {3: \"lightsalmon\", 0: \"lightcoral\", -3: \"brown\"}\n",
    "steer_by_opts = dict()\n",
    "fontsize = 24\n",
    "save_to_path = None\n",
    "\n",
    "# Prepare the data for PCA\n",
    "all_hidden_states = []\n",
    "info_levels = []\n",
    "for item in instruct_msg_dicts:\n",
    "    if item[\"info_revealing_level\"] in remove_info_levels:\n",
    "        continue\n",
    "    hs = item[\"hidden_states\"]\n",
    "    if isinstance(hs, torch.Tensor):\n",
    "        hs = hs.detach().cpu().numpy()\n",
    "    hs = hs.squeeze(0)\n",
    "    if len(all_hidden_states) == 0 and len(hs) > 1:\n",
    "        print(f\"[INFO] {len(hs)} hidden states, you are selecting the {hidden_state_idx}th one.\")\n",
    "    all_hidden_states.append(hs[hidden_state_idx])\n",
    "    info_levels.append(item[\"info_revealing_level\"])\n",
    "\n",
    "# Fit PCA\n",
    "X = np.array(all_hidden_states) # (n_samples, n_features)\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# Plot instruction PCA\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "plt.figure(figsize=(15, 8))\n",
    "scatter = plt.scatter(\n",
    "    X_pca[:, 0],\n",
    "    X_pca[:, 1],\n",
    "    c=info_levels,\n",
    "    cmap='viridis',\n",
    "    alpha=0.1 if len(steer_by_opts) > 0 else 0.4,\n",
    "    # s=50 # marker size\n",
    "    s=100 # marker size\n",
    ")\n",
    "# plt.title(\"PCA of LLM hidden states by strategy level\", fontsize=fontsize)\n",
    "plt.xlabel(f\"Principal component 1 ({pca.explained_variance_ratio_[0]:.2%})\", fontsize=fontsize, labelpad=15)\n",
    "plt.ylabel(f\"Principal component 2 ({pca.explained_variance_ratio_[1]:.2%})\", fontsize=fontsize, labelpad=15)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.gca().xaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "plt.gca().yaxis.set_major_locator(plt.MaxNLocator(5))\n",
    "cbar = plt.colorbar(scatter, pad=0.02)\n",
    "cbar.ax.tick_params(labelsize=fontsize)\n",
    "cbar.set_label(\"Information-revealing level\\n(1 = Cryptic, 10 = Revealing)\", fontsize=fontsize, labelpad=75, rotation=270)\n",
    "\n",
    "# Add the steering vector arrow\n",
    "if add_steering_vec:\n",
    "    if \"steering_vector_np\" not in globals():\n",
    "        print(\"[WARNING] Steering vector not found. Please compute it first before adding it to the PCA plot.\")\n",
    "    else:\n",
    "        projected_steering_vector = -steering_vector_np @ pca.components_.T\n",
    "        plt.arrow(\n",
    "            x=0,\n",
    "            y=0,\n",
    "            dx=projected_steering_vector[0],\n",
    "            dy=projected_steering_vector[1],\n",
    "            color='tab:red',\n",
    "            width=.15,\n",
    "            head_width=0.4,\n",
    "            head_length=0.3,\n",
    "            length_includes_head=False,\n",
    "            zorder=2, # Draw arrow on top of scatter points\n",
    "            label='Steering direction'\n",
    "        )\n",
    "        plt.legend(loc='upper left', fontsize=fontsize-2, framealpha=1)\n",
    "\n",
    "# Plot no-instruction PCA\n",
    "all_hidden_states_new = {k: [] for k in steer_by_opts.keys()}\n",
    "labels_new = {k: f\"Steering strength {k}\" for k in steer_by_opts.keys()}\n",
    "colors_new = {k: [] for k in steer_by_opts.keys()}\n",
    "for item in no_instruct_msg_dicts:\n",
    "    for steering_strength, steering_color in steer_by_opts.items():\n",
    "        hs = item[\"hidden_states\"] + steering_strength * steering_vector_np\n",
    "        if isinstance(hs, torch.Tensor):\n",
    "            hs = hs.detach().cpu().numpy()\n",
    "        all_hidden_states_new[steering_strength].append(hs.squeeze())\n",
    "        colors_new[steering_strength].append(steering_color)\n",
    "X_pca_new = {k: pca.transform(np.array(all_hidden_states_new[k])) for k in all_hidden_states_new.keys()}\n",
    "\n",
    "for k in X_pca_new.keys():\n",
    "    print(f\"Shape of new PCA data: {X_pca_new[k].shape}\")\n",
    "\n",
    "scatter_news = []\n",
    "for steering_strength, steering_color in steer_by_opts.items():\n",
    "    if steering_strength not in X_pca_new:\n",
    "        continue\n",
    "    scatter_news.append(plt.scatter(\n",
    "        X_pca_new[steering_strength][:, 0],\n",
    "        X_pca_new[steering_strength][:, 1],\n",
    "        c=colors_new[steering_strength],\n",
    "        label=labels_new[steering_strength],\n",
    "        cmap='plasma', # 'viridis', 'plasma', 'coolwarm' are good options\n",
    "        alpha=1,\n",
    "        s=110, # marker size\n",
    "        # s=190, # marker size\n",
    "        marker='^'\n",
    "    ))\n",
    "    plt.legend(handles=scatter_news, loc='best', fontsize=fontsize-2, framealpha=1)\n",
    "\n",
    "plt.grid(True, which='both', linestyle='--', linewidth=0.5, alpha=0.6)\n",
    "plt.ylim(None, 4.2)\n",
    "if save_to_path is not None:\n",
    "    plt.savefig(save_to_path, bbox_inches='tight')\n",
    "    print(f\"Saved PCA figure to {save_to_path}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb1dc01",
   "metadata": {},
   "source": [
    "## Steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba577ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the steering vector\n",
    "print(\"Computing the steering vector...\")\n",
    "info_level_start, info_level_end = 3, 9\n",
    "hidden_state_idx = 0\n",
    "all_hidden_states = {info_level_start: [], info_level_end: []}\n",
    "for item in instruct_msg_dicts:\n",
    "    if item[\"info_revealing_level\"] not in all_hidden_states:\n",
    "        continue\n",
    "\n",
    "    hs = item[\"hidden_states\"].detach().cpu().numpy().squeeze(0) # (n_hidden_states, hidden_state_dim)\n",
    "    if len(all_hidden_states[item[\"info_revealing_level\"]]) == 0 and len(hs) > 1:\n",
    "        print(f\"[INFO] {len(hs)} hidden states, you are selecting the {hidden_state_idx}th one.\")\n",
    "    all_hidden_states[item[\"info_revealing_level\"]].append(hs[hidden_state_idx])\n",
    "\n",
    "# Compute difference-in-means steering vector\n",
    "mean_start = np.mean(all_hidden_states[info_level_start], axis=0)\n",
    "mean_end = np.mean(all_hidden_states[info_level_end], axis=0)\n",
    "steering_vector_np = mean_end - mean_start\n",
    "steering_vector_norm_orig = np.linalg.norm(steering_vector_np)\n",
    "print(f\"Steering vector norm (original): {steering_vector_norm_orig:.4f}\")\n",
    "\n",
    "# Normalize and convert to a PyTorch tensor\n",
    "steering_vector_np /= steering_vector_norm_orig\n",
    "steering_vector = torch.tensor(steering_vector_np, dtype=torch.float32)\n",
    "\n",
    "# Save\n",
    "torch.save(steering_vector, os.path.join(os.environ[\"DATA_DIR\"], \"chameleon\", f\"steering_vector_{cfg['run_time']}.pt\"), pickle_module=dill)\n",
    "print(f\"Steering vector saved to: \", os.path.join(os.environ['DATA_DIR'], 'chameleon', f\"steering_vector_{cfg['run_time']}.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902bc283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess instruct_msg_dicts - combine responses with the same game state but different info revealing levels\n",
    "instruct_msg_dicts_uniq = []\n",
    "for item in instruct_msg_dicts:\n",
    "    if len(instruct_msg_dicts_uniq) > 0 \\\n",
    "        and item[\"category\"] == instruct_msg_dicts_uniq[-1][\"category\"] \\\n",
    "        and item[\"secret_word\"] == instruct_msg_dicts_uniq[-1][\"secret_word\"]:\n",
    "        instruct_msg_dicts_uniq[-1][\"responses\"][item[\"info_revealing_level\"]] = item[\"response_text\"]\n",
    "        instruct_msg_dicts_uniq[-1][\"hidden_states\"][item[\"info_revealing_level\"]] = item[\"hidden_states\"]\n",
    "    else:\n",
    "        instruct_msg_dicts_uniq.append({\n",
    "            \"category\": item[\"category\"],\n",
    "            \"secret_word\": item[\"secret_word\"],\n",
    "            \"messages\": item[\"messages\"],\n",
    "            \"responses\": {\n",
    "                item[\"info_revealing_level\"]: item[\"response_text\"]\n",
    "            },\n",
    "            \"hidden_states\": {\n",
    "                item[\"info_revealing_level\"]: item[\"hidden_states\"]\n",
    "            },\n",
    "        })\n",
    "print(f\"Unique instruction messages: {len(instruct_msg_dicts_uniq)} (originally {len(instruct_msg_dicts)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "777512e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new responses with the steering vector\n",
    "apply_steering_at_token = -1 # None means apply at all tokens\n",
    "hidden_states_layer_idx = 40\n",
    "hidden_states_token_idx = 0\n",
    "completely_replace_activations = False\n",
    "additional_generation_kwargs={\n",
    "    \"max_new_tokens\": 10,\n",
    "    \"do_sample\": False,\n",
    "    \"temperature\": None,\n",
    "    \"top_p\": None,\n",
    "    \"top_k\": None,\n",
    "}\n",
    "max_k_game_states = -1\n",
    "steering_strengths = []\n",
    "steering_strengths.extend([0, -8, -16, -32])\n",
    "steered_results = []\n",
    "data_to_steer = instruct_msg_dicts_uniq[:max_k_game_states]\n",
    "\n",
    "print(\"\\nGenerating new responses with steering vector applied...\")\n",
    "for i, item in enumerate(data_to_steer):\n",
    "    secret_word = item[\"secret_word\"]\n",
    "    print(f\"--- Processing item {i+1}/{len(data_to_steer)} (Category: {item['category']}, Secret: {secret_word}, Responses: {', '.join([it + ' (' + str(level) + ')' for level, it in item['responses'].items()])}) ---\")\n",
    "\n",
    "    # Prepare the neutral messages for this item (w/out instruction)\n",
    "    neutral_messages = list(item[\"messages\"])\n",
    "    neutral_messages[-1] = {\n",
    "        \"role\": \"user\", \"content\": RESPOND_PROMPT.format(previous_words=\"\", instruction=\"\").strip()\n",
    "    }\n",
    "\n",
    "    item_steered_responses = {\n",
    "        \"original_responses\": item[\"responses\"],\n",
    "        \"steered_outputs\": dict(),\n",
    "    }\n",
    "\n",
    "    for strength in steering_strengths:\n",
    "        # The hook will be active only inside this 'with' block\n",
    "        hook = SteeringHook(\n",
    "            model,\n",
    "            layer_index=hidden_states_layer_idx,\n",
    "            token_index=apply_steering_at_token,\n",
    "            steering_vector=steering_vector,\n",
    "            steering_strength=strength,\n",
    "            completely_replace=completely_replace_activations,\n",
    "        )\n",
    "        with hook:\n",
    "            # Get the response\n",
    "            talker = HuggingfaceTalker(\n",
    "                model_id=model.name_or_path,\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                additional_generation_kwargs=additional_generation_kwargs,\n",
    "                hidden_states_layer_idx=hidden_states_layer_idx,\n",
    "                hidden_states_token_idx=hidden_states_token_idx,\n",
    "                start_conversation=False,\n",
    "            )\n",
    "            \n",
    "            # We don't need hidden states from the steered generation, but we could get them\n",
    "            steered_response_dict = talker.get_llm_response_and_hidden_states(\n",
    "                messages=neutral_messages,\n",
    "                max_new_tokens=additional_generation_kwargs[\"max_new_tokens\"],\n",
    "                return_logprobs=True,\n",
    "                get_all_logprobs=True,\n",
    "            )\n",
    "            steered_response, steered_hidden_states = steered_response_dict[\"content\"], steered_response_dict[\"hidden_states\"]\n",
    "            logprobs = steered_response_dict.get(\"logprobs\", None)\n",
    "        \n",
    "        # Store the results\n",
    "        item_steered_responses[\"steered_outputs\"][strength] = {\n",
    "            \"response\": steered_response,\n",
    "            \"hidden_states\": steered_hidden_states,\n",
    "            \"logprobs\": logprobs,\n",
    "        }\n",
    "\n",
    "    steered_results.append(item_steered_responses)\n",
    "    print(f\"  Steered responses: {', '.join([it['response'] + ' (' + str(strength) + ')' for strength, it in item_steered_responses['steered_outputs'].items()])}\")\n",
    "\n",
    "# Save the steered results\n",
    "save_to_path = os.path.join(os.environ[\"DATA_DIR\"], \"chameleon/steering\", f\"steered_results_{cfg['run_time']}.pkl\")\n",
    "with open(save_to_path, \"wb\") as f:\n",
    "    pickle.dump(steered_results, f)\n",
    "print(f\"Saved steered results to:\\n\", save_to_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0012e801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "only_strengths = [0, -8, -16, -32, -64]\n",
    "for i, (item, orig_item) in enumerate(zip(steered_results, instruct_msg_dicts_uniq)):\n",
    "    print(\n",
    "        f\"{orig_item['category']}  :  {orig_item['secret_word']}\\n\"\n",
    "        f\"Original (info-revealing level): {', '.join([it + ' (' + str(level) + ')' for level, it in item['original_responses'].items()])}\\n\"\n",
    "        f\"Steered (strength):  {', '.join([it['response'] + ' (' + str(strength) + ')' for strength, it in item['steered_outputs'].items() if strength in only_strengths])}\"\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
